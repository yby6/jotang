# A Watermark for Large Language Models

## 1. Introduction

1. 提出了五个基本原则
   - 不需要调用LLM模型。使得模型快速，便宜
   - 水印文本可以使用标准语言模型生成，不需要重新训练
   - 水印只能从生成文本的连续部分检测到
   - 不修改大量令牌，就无法删除水印
   - 对水印的检测，有严格的统计结果
2. 对低熵文本(很确定的文本，例如论文中提到的循环语句)效果不好
   - 人类和计算机可能会输出极为相似的句子
   - 对标记的选择，可能会导致高困惑度，甚至错误的回答出现

## 2. A simple proof of concept

一个简单的预测办法：

1. 步骤：
   - 首先根据现有的生成序列预测下一个单词
   - 然后根据最后一个单词确定随机种子
   - 从随机种子中选出红令牌以及绿令牌
   - 最后预测，只选择绿令牌里面的
2. 证明了其可行性：
   - 若是想要篡改，至少要修改1/4的令牌
   - 在很短的文本，人类也有1/2的概率会大量使用红令牌里面的内容，所以可以被检测到

### 3. A more sophisticated watermark

一个更复杂的方法：

1. 改进方法：针对每次模型输出的预测向量，对绿名单的tokens,加上一个常数，相当于提高了他的权重，但是对红名单里面的tokens，如果有很大的概率，也能输出，使输出更加准确。
2. 用z来评判输出质量，当z为正数，在平均值之上，当z为负数，在平均值之下

### 4. Analysis of the soft watermark

1. 定义了一个尖峰熵，衡量预测词的分布情况
2. 还提出了，如果一个词，用的次数太多的解决办法，通过第一次记录，后面不记录的方法，进行改进

### 5. Private Watermarking

1. 利用hash值，利用随机种子，来生成红色列表，实现水印算法的安全性

### 6. Experiments

1. 多项式采样生成文本

2. 当$\gamma$很小的时候，$\delta$​ 很大的时候，水印的效果比较好，但是文本的质量与之成反比

   ![](截图\PixPin_2024-09-28_14-03-09.png)

3. 其中还提到了Beam Search（类似于贪心算法，但是比贪心算法效果更好，因为考虑了多个结果，每次保留较高的概率）假如和水印方法一起使用的话，对文本质量基本没有影响

   ![](截图\PixPin_2024-09-28_14-05-42.png)

4. 随后尝试了很多的参数组合，更小的$\gamma$，更大的$\delta$​，导致z-score更大

### 7. Attacking the watermark

- 大的策略：

  1. 文本插入：可能改变后面的红名单

  2. 文本删除

  3. 文本替换

- 利用其他的文本模型对文章进行重新编写

- 拼错单词，添加空格（但一个良好的方法，这个攻击不应该产生影响）

- 更换语言表达方式

### 8. Related Work

- 自然语言水印，用数字形式等自然文本语言
- 事后检测，对生产文本进行检测，但是随着大模型的发展，这种方法越来越不可能

## 自己的理解

1. hard watermark：

   - 步骤：

     - 首先根据现有的生成序列预测下一个单词

     - 然后根据最后一个单词确定随机种子

     - 从随机种子中选出红令牌以及绿令牌

     - 最后预测，只选择绿令牌里面的

2. soft watermark：

   - 只是让红令牌出现的概率更低，而不是完全不出现

3. 

   - 因为这些攻击方法都是为了区分机器和人类不同的语言习惯
   - 这篇论文提到的方法和自然语言水印，都是通过让机器输出一些人类输出，但是机器少输出的字符，以此区分

   - 如果里面这些字符比较多，那么大概率是机器写的，否则则是人
   - 剩余一种则完全便是让机器自己学习，自己区分，直接事后分析，相当于二分类





