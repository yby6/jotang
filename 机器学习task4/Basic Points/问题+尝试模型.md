# 问题

1. **logits是什么**：logits是在经过softmax处理之前，最后一层线性变化处理之后，神经网络输出的值，可以认为是每一个类别的置信值，概率，但是加起来，不为1，经过softmax之后，便转换为所有概率加起来为1的概率值

2. **softmax是什么**：是一种数学函数，将所有的logits置信值的概率分布，归一化，将所有的分布加起来为1，结合交叉熵损失函数，还能进行误差分析

   公式如下：
   $$
   \sigma(zi) = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}
   $$

3.  **Attention**:

   - 含义：让模型对输入的数据，关注的程度不同，提高关联性比较大的部分的注意程度

   - 分类：

     - soft attention：计算每一个输入的注意力权重，经过softmax，再加权平均，得到结果

     - hard attention：抽样选择，采样，只关注输入某一个特定的部分

   - 例如自注意力（soft attention)
     - 先将输入序列通过嵌入层(将输入转换为连续向量)转换为向量
     - 通过线性层生成kqv
     - 用查询和键计算注意力权重，再经过softmax
     - 最后将注意力权重与值向量做加权求和

4. **Transformer**:

   - 先用生成kqv

   - 再加上位置编码

   - 然后再运用多头注意力

   - 再用残差连接和层归一化

   - 然后再进入前馈神经网络(线性层和激活函数)

   - 最后残差连接和层归一化

     <img src="屏幕截图 2024-09-04 101645.png" style="zoom: 50%;" />

5. **LLM基本架构**：

   - Transform架构
     - 首先进行词嵌入，转换为token
     - 再加上位置编码
     - 编码层：自注意力机制，多头注意力
     - 再加上前馈神经网络
     - 再加上残差连接和层归一化
   - 自回归注意力机制
     - 在生成每个新的元素的时候，模型仅仅依赖于已经生成的元素，不依赖于未来的信息
     - 实现方式：主要通过掩码机制实现

# 尝试模型

1. 尝试情感判断模型，运行结果

   ![](图片\运行结果.png)

2. 尝试语言预测模型，运行结果

   ![](图片\PixPin_2024-10-02_14-51-24.png)