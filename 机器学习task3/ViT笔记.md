# ViT

## 总体笔记

### 1. Abstract

1. 总体介绍前人的工作，和自己的思考，前面的很多实验，虽然想到引入Transform，但是还是用到了卷积神经网络之类的，没有完整的保留Transform，但这里便完整的保留了Transform

### 2. Introduction

1. 总体介绍写作原因，以及背景，前人所做的工作，讲述自己与他们的差别。
2. 数据量太小的时候，c训练出的模型表现不是特别好
3. 同时用的计算机视觉常用的有监督的学习，而不是NLP领域常用的无监督的学习

### 3. Related work

1. 简述NLP的状况，大数据集上学习，再在下游任务微调
2. 若如像素为基本训练单位，放在Transform里面，数据量太大，目前还无法训练
   - 例如，一张224*224的图片，便有50176个像素，而bert之类的大模型也才几百

3. 其实前面也有学者做过patch2*2的，但比较适用于小分辨率

  ### 4. Method

![](图片\ViT.png)

- 模型图：
  1. 首先把一张图片分割成为一个一个的patch
     - 例如：一张224\*224的图片，如果分为16\*16的patch，可以分为196个小的patch输入（比较符合要求，长度适中）
  2. 放进线性处理层，展开，并且做一个线性映射，便于后面放进Transform里面学习
  3. 并且还把图片做了位置编码，便于模型学习到位置信息
  4. 把两个相加，一起放入Transform
  5. Transform的结构便是一个标准的结构
  6. 除此之外，还加了一个分类头，后面便根据这个来进行图片分类
  7. 最后放入一个MLP进行分类
- 位置编码使用的是1D，后面可以看到2D的位置编码，没有很明显的效果提升，1D便能很好的学到位置信息
- 卷积神经网络里的先验知识，明显更多，比如平移不变，局部相似，但是ViT用的基本没有
- 也还可以将CNN处理后的输出，放入Transform中学习
- 如果图形大小变化，便使用插值，补充

### 4. Experiment

1. 自监督，也有还不错的效果
1. 结果：效果非常好，相比于其他的模型，训练时间也更短
1. 在小的数据集的时候ViT的表现，不如CNN，大概是因为没有先验知识，在中等数据集，两者效果差不多，但在大的数据集上效果十分明显
1. 还比较了混合模型，开始混合模型比较好，但随着数据量的增大，ViT的效果也变好了
1. 而且目前看来模型仍旧没有饱和的现象
1. 注意距离 = 实际距离 * 注意力

### 5. Conclusion

1. ViT还可以用于其他任务，如图像分割，目标识别（Swin Transformer）


## ViT和CNN的区别

1. 同：
   - 用于图像处理

2. 异：

   - ViT用transform来提取图像特征，而CNN用卷积神经网络
   - ViT相对于CNN有更少的先验知识

3. ViT

   - 优点：

     - 当数据集足够大的时候，ViT显示出优良的性能

     - 使CV和NLP能够使用一个统一的架构来进行图像处理

   - 缺点：
     - 需要大量的数据，当数据集比较小的时候，其表现还不如CNN

5. CNN：
   - 优点：
     - 比较擅长于图片处理，即使非常小的数据集，也能够得到比较不错的效果
     - 计算效率比较高
   - 缺点：
     - 设置网络时，根据不同问题，要设置不同的网络，而且随着问题，越来越复杂，CNN的设计，越来越复杂

## 实验结果

1. 对比

   |                    | ResNet |  ViT   |
   | :----------------: | :----: | :----: |
   | 训练时间(预训练后) |  20轮  |  3轮   |
   |     最终准确率     | 90.86% | 97.95% |
   |      收敛速度      |  较快  |  较慢  |

   

2. 分析：

   - 性能在小数据集上差距不是特别大，ResNet在训练一定轮数之后也能达到相同的效果

   - ViT是借用了预训练模型的数据，但是刚开始训练的时候，效果就很不错，说明其下游任务的迁移效果还不错

   - Patch Size的影响，因为在比较小的数据集上面，所以差距不大

     | Patch Size | 轮数 | 准确度 |
     | :--------: | :--: | :----: |
     |     8      |  3   | 98.35% |
     |     16     |  3   | 97.91% |
     |     32     |  3   | 97.94% |

     但是按照，理论来分析，当Patch Size更小时，并且要在Trasform能够处理的范围内，效果应该会更好，因为能够捕捉更加细微的局部细节，虽然会导致更加多的patch，增加计算量