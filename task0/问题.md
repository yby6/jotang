## 问题

- **监督学习与无监督学习的区别**：

  1. 监督学习使用的是有标签的数据，而无监督学习使用的是没有标签的数据

  2. 监督学习一般都有明确的目标，通过对有数据有标签的数据，进行学习之后，进而对有数据无标签的数据进行分类；而无监督学习则是通过计算机自己学习，寻找其中的潜在联系

- **机器学习与深度学习的区别**：

  1. 两者关系：深度学习是机器学习的一个子集
  2. 两者都是自己学习，但是深度学习则是模拟人脑，使用多层神经网络来学习
  3. 深度学习一般来说模型比机器学习更加复杂，而且所需要的数据集更大，机器学习大多，可能只需要cpu，但是深度学习则会用到GPU甚至TPU，以及专有芯片

- **偏导数、链式法则、梯度、矩阵等在机器学习中的作用**

  - **偏导数**
    1. 在损失函数优化的时候，需要计算梯度，便要用到偏导数
  - **链式法则**
    1. 在反向传播时，需要计算每一层的梯度，进而优化，这里便要用到反向传播
  - **梯度**
    1. 在反向传播，中链式法则中便会用到
  - **矩阵**
    1. 输入神经网络的数据，便是用矩阵描述的，这样方便进行高效计算，以及层的权重矩阵也是通过矩阵表示的

- **激活函数**：

  1. 作用：引入非线性，使模型有更好的拟合能力，可以拟合更加复杂的数据，否则的话，只能拟合简单的数据

  2. 常见激活函数：

     - sigmoid
       $$
       \text{Sigmoid}(x) = \frac{1}{1 + e^{-x}}
       $$
       

     - tanh
       $$
       \text{tanh}(x)= \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
       $$
       

     - ReLU 及其变种Leaky ReLU和Parametric ReLU（PReLU)

     $$
     \text{ReLU(x)} = \text{max(0,x)}
     $$

- 神经网络的基本结构

  1. 输入层：接受输入数据

  2. 隐藏层：对数据进行处理，自动学习数据之中的特征

  3. 输出层：输出预测结果

  4. 激活函数：存在于隐藏层和输出层里面

  5. 优化算法：Adam，SGD等

  6. 损失函数：

     ```python
     criterion = nn.MSELoss()
     criterion = nn.CrossEntropyLoss()等
     ```

- 机器学习中的数据处理

  1. 首先选择是否需要在GPU上处理数据

     ```python
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
     ```

  2. 读取数据（分为不同的类型）

     - 为csv或者tsv文件
     - 图片，每一个文件夹为一个类型
     - 标签和图片分开在两个文件夹

  3. 数据分析：大致了解数据，看其中数据类型，是否有缺失值等

     ```python
     # 看一下数据长什么样
     print(train_data.head())
     # 看一下数据的基本的统计信息
     print(train_data.describe())
     # 看一下缺失值和数据类型
     print(train_data.info())
     ```

  4. 数据可视化：运用图表进行可视化
  5. 数据处理：
     - 缺失值处理
     - 将不是数值类型的转换，编码
     - 提取新的特征
     - 转换为torch向量

  6. 批量处理：
  7. 使用dataset，dataloader训练









